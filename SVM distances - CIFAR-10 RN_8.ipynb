{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.datasets import cifar10\n",
    "import keras.backend as K\n",
    "\n",
    "from pgd_attack import AdversarialExampleGenerator\n",
    "from svm_model import SVMModel\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import math\n",
    "from statistics import mean, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 8 / 255\n",
    "batch_size = 64\n",
    "model_path = \"saved_models/CIFAR10_SmallResNet_eps_0.031/Apr26_17-05-26/weights_050_0.39.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000 train samples\n",
      "5000 validation samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Data preparation #\n",
    "####################\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Leave aside a validation set\n",
    "x_valid = x_train[-5000:]\n",
    "y_valid = y_train[-5000:]\n",
    "x_train = x_train[:-5000]\n",
    "y_train = y_train[:-5000]\n",
    "\n",
    "# Input image dimensions\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_valid = x_valid.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_valid.shape[0], \"validation samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# Model initialisation #\n",
    "########################\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "model.xent_loss = model.total_loss\n",
    "for loss in model.losses:\n",
    "    model.xent_loss -= loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Data generators #\n",
    "###################\n",
    "\n",
    "valid_adv_generator = AdversarialExampleGenerator(model, x_valid, y_valid,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  epsilon=epsilon,\n",
    "                                                  k=40,\n",
    "                                                  a=epsilon / 10.0,\n",
    "                                                  incremental=False,\n",
    "                                                  shuffle=False)\n",
    "\n",
    "test_adv_generator  = AdversarialExampleGenerator(model, x_test, y_test,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  epsilon=epsilon,\n",
    "                                                  k=40,\n",
    "                                                  a=epsilon / 10.0,\n",
    "                                                  incremental=False,\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [29:17<00:00, 24.21s/it]\n",
      "100%|██████████| 157/157 [1:24:51<00:00, 24.59s/it]\n"
     ]
    }
   ],
   "source": [
    "x_acc = []\n",
    "for x_batch, _, _ in tqdm(valid_adv_generator):\n",
    "    x_acc.append(x_batch)\n",
    "x_valid_adv = np.concatenate(x_acc, axis=0)\n",
    "\n",
    "x_acc = []\n",
    "for x_batch, _, _ in tqdm(test_adv_generator):\n",
    "    x_acc.append(x_batch)\n",
    "x_test_adv = np.concatenate(x_acc, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = model.input\n",
    "output_tensor = model.layers[-2].output\n",
    "\n",
    "representation_model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "train_nat_representations = representation_model.predict(x_train)\n",
    "valid_nat_representations = representation_model.predict(x_valid)\n",
    "valid_adv_representations = representation_model.predict(x_valid_adv)\n",
    "test_nat_representations = representation_model.predict(x_test)\n",
    "test_adv_representations = representation_model.predict(x_test_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1)\n",
    "y_valid = y_valid.reshape(-1)\n",
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVMModel(train_nat_representations, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict_valid_nat = np.argmax(model.predict(x_valid), axis=1)\n",
    "model_predict_valid_adv = np.argmax(model.predict(x_valid_adv), axis=1)\n",
    "\n",
    "svm_predict_valid_nat = svm_model.predict(valid_nat_representations)\n",
    "svm_predict_valid_adv = svm_model.predict(valid_adv_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How good is the SVM as an approximation to the output layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM natural train accuracy 0.8362888888888889\n",
      "Model natural train accuracy 0.8034222222222223\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM natural train accuracy\", svm_model.test(train_nat_representations, y_train))\n",
    "print(\"Model natural train accuracy\", model.evaluate(x_train, y_train, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM natural valid accuracy 0.7698\n",
      "Model natural valid accuracy 0.7436\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM natural valid accuracy\", svm_model.test(valid_nat_representations, y_valid))\n",
    "print(\"Model natural valid accuracy\", model.evaluate(x_valid, y_valid, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM adversarial valid accuracy 0.3626\n",
      "Model adversarial valid accuracy 0.3872\n"
     ]
    }
   ],
   "source": [
    "# Adversarial train accuracy\n",
    "print(\"SVM adversarial valid accuracy\", svm_model.test(valid_adv_representations, y_valid))\n",
    "print(\"Model adversarial valid accuracy\", model.evaluate(x_valid_adv, y_valid, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 natural valid concurrence of SVM 0.866\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Top 1 natural valid concurrence of SVM\",\n",
    "    np.count_nonzero(svm_predict_valid_nat == model_predict_valid_nat) / len(x_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 adversarial valid concurrence of SVM 0.807\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Top 1 adversarial valid concurrence of SVM\",\n",
    "    np.count_nonzero(svm_predict_valid_adv == model_predict_valid_adv) / len(x_valid_adv)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 natural valid concurrence of SVM 0.9618\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for p, q in zip(svm_model.predict(valid_nat_representations), np.argsort(model.predict(x_valid), axis=1)[:, -2:]):\n",
    "    if p in q:\n",
    "        count += 1\n",
    "print(\"Top 2 natural valid concurrence of SVM\", count / len(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 adversarial valid concurrence of SVM 0.9532\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for p, q in zip(svm_model.predict(valid_adv_representations), np.argsort(model.predict(x_valid_adv), axis=1)[:, -2:]):\n",
    "    if p in q:\n",
    "        count += 1\n",
    "print(\"Top 2 adversarial valid concurrence of SVM\", count / len(x_valid_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latexify(fig_width=None, fig_height=None, columns=1):\n",
    "    \"\"\"Set up matplotlib's RC params for LaTeX plotting.\n",
    "    Call this before plotting a figure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fig_width : float, optional, inches\n",
    "    fig_height : float,  optional, inches\n",
    "    columns : {1, 2}\n",
    "    \"\"\"\n",
    "\n",
    "    # code adapted from http://www.scipy.org/Cookbook/Matplotlib/LaTeX_Examples\n",
    "\n",
    "    # Width and max height in inches for IEEE journals taken from\n",
    "    # computer.org/cms/Computer.org/Journal%20templates/transactions_art_guide.pdf\n",
    "\n",
    "    assert(columns in [1,2])\n",
    "\n",
    "    if fig_width is None:\n",
    "        fig_width = 3.39 if columns==1 else 6.9 # width in inches\n",
    "\n",
    "    if fig_height is None:\n",
    "        golden_mean = (math.sqrt(5)-1.0)/2.0    # Aesthetic ratio\n",
    "        fig_height = fig_width*golden_mean # height in inches\n",
    "    \n",
    "    MAX_HEIGHT_INCHES = 8.0\n",
    "    if fig_height > MAX_HEIGHT_INCHES:\n",
    "        print(\"WARNING: fig_height too large:\" + fig_height + \n",
    "              \"so will reduce to\" + MAX_HEIGHT_INCHES + \"inches.\")\n",
    "        fig_height = MAX_HEIGHT_INCHES\n",
    "\n",
    "    params = {'backend': 'ps',\n",
    "              'text.latex.preamble': [\"\\\\usepackage[lf,minionint,footnotefigures]{MinionPro}\"],\n",
    "              'axes.labelsize': 8, # fontsize for x and y labels (was 10)\n",
    "              'axes.titlesize': 8,\n",
    "#               'text.fontsize': 8, # was 10\n",
    "              'legend.fontsize': 8, # was 10\n",
    "              'xtick.labelsize': 8,\n",
    "              'ytick.labelsize': 8,\n",
    "              'text.usetex': True,\n",
    "              'figure.figsize': [fig_width, fig_height],\n",
    "              'font.family': 'serif',\n",
    "              'mathtext.default': 'regular'\n",
    "    }\n",
    "\n",
    "    matplotlib.rcParams.update(params)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "latexify(fig_width=2.6, fig_height=2.0951352218621437)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_dir = \"figures\"\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  alternative=\"'density'\", removal=\"3.1\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 187.2x150.85 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_nat_dists = svm_model.get_predicted_class_decision_boundary_distances(\n",
    "                             valid_nat_representations,\n",
    "                             svm_predict_valid_nat)\n",
    "\n",
    "valid_adv_dists = svm_model.get_predicted_class_decision_boundary_distances(\n",
    "                             *zip(*[(x,y) for (x,y,z) in  zip(\n",
    "                                 valid_adv_representations,\n",
    "                                 svm_predict_valid_adv,\n",
    "                                 y_valid\n",
    "                             ) if y != z])\n",
    "                         )\n",
    "\n",
    "nat_min_dists = list(map(lambda xs: min(xs), valid_nat_dists))\n",
    "adv_min_dists = list(map(lambda xs: min(xs), valid_adv_dists))\n",
    "\n",
    "# plt.title(\"Min distance in natural model\")\n",
    "plt.hist(nat_min_dists, normed=True, bins=25, alpha=0.5, label=\"Natural\")\n",
    "plt.hist(adv_min_dists, normed=True, bins=25, alpha=0.5, label=\"Adversarial\")\n",
    "plt.legend()\n",
    "# plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.gca().set_xlim([-4, 14])\n",
    "plt.gca().set_ylim([0, 0.6])\n",
    "plt.grid(True, \"both\", linestyle=\"dotted\")\n",
    "for tic in plt.gca().yaxis.get_major_ticks():\n",
    "    tic.tick1On = tic.tick2On = False\n",
    "    tic.label1On = tic.label2On = False\n",
    "plt.savefig(os.path.join(figures_dir, \"svm_dists_cifar10_RN_8_eps_8.pdf\"), bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7874 accuracy on natural images\n",
      "0.7736 accuracy on adversarial images\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(representations, predictions, y, is_adv, adv_pred_function):\n",
    "    dists = svm_model.get_predicted_class_decision_boundary_distances(\n",
    "                                 representations,\n",
    "                                 predictions)\n",
    "        \n",
    "    if not is_adv:\n",
    "        correct_predict = [not adv_pred_function(xs) and a == b\n",
    "                           for (xs,a,b) in zip(dists, predictions, y)]\n",
    "    else:\n",
    "        correct_predict = [adv_pred_function(xs) or a == b\n",
    "                           for (xs,a,b) in zip(dists, predictions, y)]\n",
    "    \n",
    "    return np.sum(correct_predict) / len(representations)\n",
    "\n",
    "adv_pred_function = lambda xs: min(xs) < 0.75\n",
    "\n",
    "print(calculate_accuracy(valid_nat_representations,\n",
    "                         svm_predict_valid_nat,\n",
    "                         y_valid,\n",
    "                         False,\n",
    "                         adv_pred_function),\n",
    "      \"accuracy on natural images\")\n",
    "\n",
    "\n",
    "print(calculate_accuracy(valid_adv_representations,\n",
    "                         svm_predict_valid_adv,\n",
    "                         y_valid,\n",
    "                         True,\n",
    "                         adv_pred_function),\n",
    "      \"accuracy on adversarial images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
