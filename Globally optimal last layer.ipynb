{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model, clone_model, Model, Sequential\n",
    "from keras.layers import Activation, Dense, Softmax\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from pgd_attack import AdversarialExampleGenerator\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "# Restrict GPU memory usage\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = \"0\"\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 8 / 255\n",
    "batch_size = 64\n",
    "model_path = \"saved_models/CIFAR10_SmallResNet_eps_0.031/Apr26_17-05-26/weights_050_0.39.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (45000, 32, 32, 3)\n",
      "y_train shape: (45000, 1)\n",
      "45000 train samples\n",
      "5000 validation samples\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Data preparation #\n",
    "####################\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Leave aside a validation set\n",
    "x_valid = x_train[-5000:]\n",
    "y_valid = y_train[-5000:]\n",
    "x_train = x_train[:-5000]\n",
    "y_train = y_train[:-5000]\n",
    "\n",
    "# Input image dimensions\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_valid = x_valid.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_valid.shape[0], \"validation samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 16)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 16)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 16)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 32)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 32)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 32)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 8, 8, 64)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 8, 8, 64)     0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8, 8, 64)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# Model initialisation #\n",
    "########################\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 16)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 16)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 16)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 32)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 32)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 32)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 8, 8, 64)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 8, 8, 64)     0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8, 8, 64)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 650\n",
      "Non-trainable params: 273,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "frozen_model = clone_model(model)\n",
    "\n",
    "# For some reason we have to re-load the weights\n",
    "frozen_model.load_weights(model_path)\n",
    "\n",
    "for l in frozen_model._layers[:-1]:\n",
    "    l.trainable = False\n",
    "\n",
    "frozen_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                     optimizer=Adam(lr=1e-4),\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "frozen_model.xent_loss = frozen_model.total_loss\n",
    "for loss in frozen_model.losses:\n",
    "    frozen_model.xent_loss -= loss\n",
    "\n",
    "frozen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Data generators #\n",
    "###################\n",
    "\n",
    "train_generator = AdversarialExampleGenerator(frozen_model, x_train, y_train,\n",
    "                                              batch_size=batch_size,\n",
    "                                              epsilon=epsilon,\n",
    "                                              k=8,\n",
    "                                              a=0.03,\n",
    "                                              incremental=False)\n",
    "test_generator =  AdversarialExampleGenerator(frozen_model, x_test, y_test,\n",
    "                                              batch_size=batch_size,\n",
    "                                              epsilon=epsilon,\n",
    "                                              k=40,\n",
    "                                              a=epsilon / 10.0,\n",
    "                                              incremental=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7715986221313476, 0.3782]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################\n",
    "# Initial performance #\n",
    "#######################\n",
    "\n",
    "frozen_model.evaluate_generator(test_generator, workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "704/704 [==============================] - 518s 736ms/step - loss: 1.3248 - acc: 0.5312 - val_loss: 1.7760 - val_acc: 0.3793\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 520s 739ms/step - loss: 1.3238 - acc: 0.5334 - val_loss: 1.7767 - val_acc: 0.3799\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 518s 735ms/step - loss: 1.3210 - acc: 0.5347 - val_loss: 1.7785 - val_acc: 0.3789\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 517s 735ms/step - loss: 1.3246 - acc: 0.5310 - val_loss: 1.7822 - val_acc: 0.3772\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 515s 732ms/step - loss: 1.3266 - acc: 0.5290 - val_loss: 1.7827 - val_acc: 0.3776\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 818s 1s/step - loss: 1.3221 - acc: 0.5330 - val_loss: 1.7850 - val_acc: 0.3769\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 1242s 2s/step - loss: 1.3212 - acc: 0.5326 - val_loss: 1.7864 - val_acc: 0.3771\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 1299s 2s/step - loss: 1.3236 - acc: 0.5339 - val_loss: 1.7888 - val_acc: 0.3767\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 1298s 2s/step - loss: 1.3231 - acc: 0.5321 - val_loss: 1.7901 - val_acc: 0.3784\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 808s 1s/step - loss: 1.3223 - acc: 0.5309 - val_loss: 1.7914 - val_acc: 0.3787\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# Train #\n",
    "#########\n",
    "\n",
    "frozen_model_history = \\\n",
    "    frozen_model.fit_generator(train_generator,\n",
    "                               validation_data=test_generator,\n",
    "                               epochs=10,\n",
    "                               workers=0, # Important for the generators\n",
    "                               shuffle=False) # Shuffling done in the generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace output layer with stack of dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 16)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 16)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 16)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 32)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 32)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 32)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 8, 8, 64)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 8, 8, 64)     0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8, 8, 64)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 10)           13130       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 286,922\n",
      "Trainable params: 13,130\n",
      "Non-trainable params: 273,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cloned_model = clone_model(model)\n",
    "\n",
    "cloned_model.load_weights(model_path)\n",
    "\n",
    "inputs = cloned_model.input\n",
    "\n",
    "last_hidden_layer_name = \"flatten_1\"\n",
    "output_stack = Sequential([Dense(64, kernel_regularizer=l2(1e-4)), Activation(\"relu\"),\n",
    "                           Dense(64, kernel_regularizer=l2(1e-4)), Activation(\"relu\"),\n",
    "                           Dense(64, kernel_regularizer=l2(1e-4)), Activation(\"relu\"),\n",
    "                           Dense(10), Softmax()])\n",
    "outputs = output_stack(cloned_model.get_layer(last_hidden_layer_name).output)\n",
    "\n",
    "complex_output_model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "for l in complex_output_model.layers[:-2]:\n",
    "    l.trainable = False\n",
    "\n",
    "complex_output_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                             optimizer=Adam(lr=1e-4),\n",
    "                             metrics=[\"accuracy\"])\n",
    "\n",
    "complex_output_model.xent_loss = complex_output_model.total_loss\n",
    "for loss in complex_output_model.losses:\n",
    "    complex_output_model.xent_loss -= loss\n",
    "\n",
    "complex_output_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Data generators #\n",
    "###################\n",
    "\n",
    "train_generator = AdversarialExampleGenerator(complex_output_model, x_train, y_train,\n",
    "                                              batch_size=batch_size,\n",
    "                                              epsilon=epsilon,\n",
    "                                              k=8,\n",
    "                                              a=0.03,\n",
    "                                              incremental=False)\n",
    "test_generator =  AdversarialExampleGenerator(complex_output_model, x_test, y_test,\n",
    "                                              batch_size=batch_size,\n",
    "                                              epsilon=epsilon,\n",
    "                                              k=40,\n",
    "                                              a=epsilon / 10.0,\n",
    "                                              incremental=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.585489645385742, 0.0526]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################\n",
    "# Initial performance #\n",
    "#######################\n",
    "\n",
    "complex_output_model.evaluate_generator(test_generator, workers=0, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "704/704 [==============================] - 520s 739ms/step - loss: 1.8299 - acc: 0.4028 - val_loss: 1.8079 - val_acc: 0.3596\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 520s 738ms/step - loss: 1.4671 - acc: 0.4928 - val_loss: 1.7892 - val_acc: 0.3735\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 989s 1s/step - loss: 1.4107 - acc: 0.5093 - val_loss: 1.7946 - val_acc: 0.3760\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 1205s 2s/step - loss: 1.3804 - acc: 0.5161 - val_loss: 1.8112 - val_acc: 0.3686\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 1204s 2s/step - loss: 1.3694 - acc: 0.5224 - val_loss: 1.8200 - val_acc: 0.3681\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 1208s 2s/step - loss: 1.3665 - acc: 0.5220 - val_loss: 1.8275 - val_acc: 0.3687\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 1204s 2s/step - loss: 1.3602 - acc: 0.5228 - val_loss: 1.8279 - val_acc: 0.3718\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 537s 763ms/step - loss: 1.3588 - acc: 0.5235 - val_loss: 1.8310 - val_acc: 0.3738\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 517s 734ms/step - loss: 1.3556 - acc: 0.5241 - val_loss: 1.8324 - val_acc: 0.3750\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 516s 734ms/step - loss: 1.3527 - acc: 0.5256 - val_loss: 1.8270 - val_acc: 0.3752\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# Train #\n",
    "#########\n",
    "\n",
    "complex_output_model_history = \\\n",
    "    complex_output_model.fit_generator(train_generator,\n",
    "                                       validation_data=test_generator,\n",
    "                                       epochs=10,\n",
    "                                       workers=0, # Important for the generators\n",
    "                                       shuffle=False) # Shuffling done in the generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_dir = \"figures\"\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latexify(fig_width=None, fig_height=None, columns=1):\n",
    "    \"\"\"Set up matplotlib's RC params for LaTeX plotting.\n",
    "    Call this before plotting a figure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fig_width : float, optional, inches\n",
    "    fig_height : float,  optional, inches\n",
    "    columns : {1, 2}\n",
    "    \"\"\"\n",
    "\n",
    "    # code adapted from http://www.scipy.org/Cookbook/Matplotlib/LaTeX_Examples\n",
    "\n",
    "    # Width and max height in inches for IEEE journals taken from\n",
    "    # computer.org/cms/Computer.org/Journal%20templates/transactions_art_guide.pdf\n",
    "\n",
    "    assert(columns in [1,2])\n",
    "\n",
    "    if fig_width is None:\n",
    "        fig_width = 3.39 if columns == 1 else 6.9 # width in inches\n",
    "\n",
    "    if fig_height is None:\n",
    "        golden_mean = (math.sqrt(5) - 1.0) / 2.0 # Aesthetic ratio\n",
    "        fig_height = fig_width*golden_mean # height in inches\n",
    "    \n",
    "    MAX_HEIGHT_INCHES = 8.0\n",
    "    if fig_height > MAX_HEIGHT_INCHES:\n",
    "        print(\"WARNING: fig_height too large:\" + fig_height + \n",
    "              \"so will reduce to\" + MAX_HEIGHT_INCHES + \"inches.\")\n",
    "        fig_height = MAX_HEIGHT_INCHES\n",
    "\n",
    "    params = {'backend': 'ps',\n",
    "              'text.latex.preamble': [\"\\\\usepackage[lf,minionint,footnotefigures]{MinionPro}\"],\n",
    "              'axes.labelsize': 8, # fontsize for x and y labels (was 10)\n",
    "              'axes.titlesize': 8,\n",
    "#               'text.fontsize': 8, # was 10\n",
    "              'legend.fontsize': 8, # was 10\n",
    "              'xtick.labelsize': 8,\n",
    "              'ytick.labelsize': 8,\n",
    "              'text.usetex': True,\n",
    "              'figure.figsize': [fig_width, fig_height],\n",
    "              'font.family': 'serif',\n",
    "              'mathtext.default': 'regular'\n",
    "    }\n",
    "\n",
    "    matplotlib.rcParams.update(params)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "latexify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(data,\n",
    "              min_y=None,\n",
    "              max_y=None,\n",
    "              x_label=\"Epoch\",\n",
    "              y_label=\"Adversarial accuracy\",\n",
    "              y_is_percent=False,\n",
    "              y_is_log=False,\n",
    "              y_ticks=None,\n",
    "              legend=None,\n",
    "              output=\"fig.pdf\"):\n",
    "    if min_y is not None or max_y is not None:\n",
    "        plt.gca().set_ylim([min_y, max_y])\n",
    "    for i, series in enumerate(data):\n",
    "        x, y = zip(*series)\n",
    "        if legend is None:\n",
    "            plt.plot(x, y, marker=\"o\", markersize=2)\n",
    "        else:\n",
    "            plt.plot(x, y, marker=\"o\", markersize=2, label=legend[i])\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    if legend is not None:\n",
    "        plt.legend()\n",
    "    plt.grid(True, \"both\", linestyle=\"dotted\")\n",
    "    plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(1.0))\n",
    "    if y_is_percent:\n",
    "        plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(decimals=0))\n",
    "    if y_is_log:\n",
    "        plt.yscale(\"log\")\n",
    "    if y_ticks is not None:\n",
    "        plt.yticks(y_ticks)\n",
    "#     plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, output), bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.08x150.85 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [\n",
    "    zip(range(1, 11), frozen_model_history.history[\"val_acc\"]),\n",
    "    zip(range(1, 11), complex_output_model_history.history[\"val_acc\"]),\n",
    "]\n",
    "\n",
    "legend = [\"Simple output layer\", \"Complex output layer\"]\n",
    "\n",
    "save_plot(data, legend=legend, min_y=0.33, max_y=0.41, output=\"output_globally_optimal.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
